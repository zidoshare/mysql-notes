### 什么是事务

说到事务，首先想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）

mysql事务提供三个基本的事务指令：

* 可以使用`start transaction` 或者 `begin` 开启事务。
* 使用`commit`提交当前事务，此时的数据才会真正进入持久化的流程
* 使用`rollback`回滚当前事务，事务的修改会被取消
* `SET autocommit`可以启用或者禁用自动提交事务模式

默认，autocommit是被开启的，这就保证了单个语句具有原子性，当然了，这也意味着每个语句执行成功就不能使用`rollback`进行回滚了。但是语句如果执行出错，还是会被自动回滚的。如果这个时候使用开启事务的命令，autocommit就会被禁用，一直到提交或者回滚事务。

#### 原子性

> 原子性概念很简单,即事务中的所有操作要么一起都完成，要么一起都不完成，不可分割。

做一个尝试，见[1.原子性](./1.原子性)

#### 一致性

> 一致性是指在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。

#### 隔离性

> 一致性是指数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。

验证代码[2.隔离性](./2.隔离性)

#### 持久性

> 持久性是指事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

### 四个隔离级别

在理解隔离界别前，我们首先要了解数据库事务所面临的问题：脏读、幻读、不可重复读

**什么是脏读、幻读、不可重复读呢？**

* 脏读：脏读是指一个事务中访问到了另外一个事务未提交的数据。理解:两个事务完全没有隔离，彼此操作都完全看得见，这就导致了并发情况下数据不一致
* 幻读：一个事务读取2次，得到的记录条数不一致。理解：两个事务隔离了对于新增、删除数据的访问。也就是说就算其他事务新增、删除了数据，我查询一个范围的时候查到的还是我事务开始时的那些数据，不会因为其他事务的增删而导致结果出错
* 不可重复读：一个事务读取同一条记录2次，得到的结果不一致。理解：两个事务隔离了同一条记录修改，也就是说就算其他事务修改了，我看到的还是之前的，这样就能保证我针对这一条数据的逻辑一定准确

**脏读、幻读、不可重复读产生了什么问题呢？**

要回答这个问题，首先应该了解并发的概念：如果我们的所有业务请求都是**原子性**的，那么我们完全不需要担心数据的操作会超出我们的预期，例如一个业务设置某个数为2，不论十个请求还是一亿个请求进来都无所谓，反正先来后到，就算你一起来都行，最终都是一步到位。但是事与愿违，几乎不可能有这么简单的业务，起码也是`先查一查数据是不是为2，如果是2就设置为4，否则设置为8`这种级别，这时候就不能不先getData(),然后setData()了，正常情况下是这样，但是如果两个请求一起进来呢？理想情况下我们觉得因该是是a请求先查询是2然后修改成4，然后b请求查询到4修改成8，或者反过来b请求先查询是2然后修改成4，然后a请求查询到4，修改成8。然而，事与愿违的是有可能a请求查了查是2，此时b请求也查了查，嗯，是2，然后b请求率先把2改成了4。此时a请求才慢悠悠的过来改数据（**因为并发情况下，没有人能预测谁会先走到哪一步**），因为之前a已经看到了是2，所以就信誓旦旦的直接设置成4。这时，问题就来了，请问，**这段逻辑是正确的吗**？

你可能会说，其实没什么问题，影响不大，他们单个的逻辑其实是正确的，也无所谓，修改个数字而已，大不了再来一次。确实，很多情况下，就是这样，没毛病，就像电脑系统出了问题大不了重启，这种情况下，虽然逻辑可能是错误的，但是最终结果其实无关紧要，这也就是**可容忍的**

但是如果把这个数字换成自己的账户，那就**不可容忍**了

从上面的问题，可以看出，我们看问题时一定要看到这个逻辑是不是可容忍的错误，然后根据开发难度（你可能是个完全不会并发的小白）、执行效率（ab之间都互相不管对方做了啥都坚持自我其实效率是最高的）、安全性（如果是我的钱包缩水那绝对不能容忍了）等方面综合评估。

mysql无法预估开发者的容忍度，而要一步到位完全解决这三个问题，那带来的效率损失不可估量，所以它为你提供了一步一步降低错误出错的方案，帮助你去做到你最想要的权衡，这也就是事务隔离性：

mysql提供了四个隔离级别：

* `Read Uncommitted`:读未提交
* `Read Committed`: 读已提交
* `Repeatable Read`: 可重复读
* `Serializable`: 串行化

根据验证[2.隔离性](./2.隔离性)所得出的结果来看，四个隔离级别对应的结果：

* [读未提交](./2.隔离性/1.读未提交)：事务1可以读取到事务2修改过但未提交的数据（产生脏读，幻读，不可重复度）
* [读已提交](./2.隔离性/2.读已提交)：事务1只能在事务2修改过并且已提交后才能读取到事务2修改的数据（产生幻读，不可重复度）
* [可重复读](./2.隔离性/3.可重复读)：事务1只能在事务2修改过数据并提交后，自己也提交事务后，才能读取到事务2修改的数据(产生幻读)
* [串行化](./2.隔离性/4.串行化)：事务1在执行过程中完全看不到事务2对数据库所做的更新。当两个事务同时操作数据库中相同数据时，如果事务1已经在访问该数据，事务2只能停下来等待，必须等到事务1结束后才能恢复运行

但是在这里我建议记忆的顺序应该是**脏读、不可重复读、幻读**，每个隔离级别依次递增的解决每一个问题，最后通过串行化，完美解决三个问题。

### 事务的实现原理

> 实现原理其实不用到处找，官方文档就有，这里我是稍微整理了一下，具体查看地址[https://dev.mysql.com/doc/refman/5.7/en/mysql-acid.html](https://dev.mysql.com/doc/refman/5.7/en/mysql-acid.html)

#### 原子性

原子性其实代表的就是可rollback。对于此，Mysql提供一个undo log(回滚日志)的日志来实现原子性，undo log是mysql innodb存储引擎所携带的日志

当事务对数据库进行修改时，InnoDB会生成对应的undo log，然后如果需要回滚，就会调用利用undolog进行反向操作从而达到回滚的目的。

例如当update时，会记录被修改行的主键(以便知道修改了哪些行)、修改了哪些列、这些列在修改前后的值等信息，回滚时便可以使用这些信息将数据还原到update之前的状态。

知道可以回滚了，接下来就自然想到一种情况，如果事务a修改了列，但未提交，事务b再次修改此列，会发生什么情况呢？该怎么回滚呢？

根据这种思路，我做了一个尝试，重现代码见[3.修改同列](./3.修改同列)



#### 持久性

持久性是指事务一旦提交，它对数据库的改变就应该是永久性的。要实现这一点，就必须保证每一次写入都被持久化下来。

众所周知，数据库的主要瓶颈就是io，mysql提高性能关键就在于减少io。如果是为了持久性就让每次写入都放进磁盘，那么数据库效率将极低，为了能够提高效率，首先就会想到，把数据的写入放到内存中，然后定期一起写进磁盘。而mysql由此提出的解决方案为Buffer Pool,Buffer Pool中包含了磁盘中部分数据页的映射, 当取数据时，先从buffer pool中读取，如果没有则去数据库读取然后放入到buffer pool中。当写入数据时，会先写入到buffer pool中。那么buffer pool的机制是如何的呢？buffer pool

因为buffer pool的使用，使得数据库的效率大大提高了，但是却失去了持久性，因为部分数据并没有切实写进磁盘中，而是放到了内存中。当服务突然宕机，会导致还没来得及刷盘的写入操作失效。

为了解决这个问题，又引入了redo log。当事务提交时，会优先写入redo log，然后再写入到buffer pool中。当服务突然宕机后，会根据redolog来进行数据恢复。

但是这又引入了新的问题，redolog也是磁盘io操作，它的性能问题又怎么办呢？
* 首先，虽然redolog是io操作，但是它与buffer pool的不同在于，它是顺序io，顺序io操作会明显快于随机io。
* buffer pool并不是以每条数据为单位的，而是为了效率以数据页为单位，mysql默认数据也大小为16kb。一个page上有很多数据，任何一个小修改都会需要刷入磁盘。而redolog是以一条条操作为单位，不会写入其他数据，写入量大大减小。

当然了，尽管如此，每次操作都会附带io仍然会降低性能。为之，就像套娃一样，mysql又为redolog提供了不同的写入时机：
* 